<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/openai-lies-rebus-800x450.png" alt="Will ChatGPTâ€™s hallucinations be allowed to ruin your life?">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/openai-lies-rebus.png" class="enlarge-link" data-height="1080" data-width="1920">Enlarge</a> (credit: Aurich Lawson)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Bribery. Embezzlement. Terrorism.</p>
<p>What if an AI chatbot accused you of doing something terrible? When bots make mistakes, the false claims can ruin lives, and the legal questions around these issues remain murky.</p>
<p>That's according to several people suing the biggest AI companies. But chatbot makers hope to avoid liability, and a string of legal threats has revealed how easy it might be for companies to wriggle out of responsibility for allegedly defamatory chatbot responses.</p></div><p><a href="https://arstechnica.com/?p=1970029#p3">Read 76 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1970029&comments=1">Comments</a></p>